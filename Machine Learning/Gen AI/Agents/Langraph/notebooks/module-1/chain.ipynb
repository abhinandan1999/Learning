{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbf2458",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/chain.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238466-lesson-4-chain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Chain\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a simple graph with nodes, normal edges, and conditional edges.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's build up to a simple chain that combines 4 concepts.\n",
    "\n",
    "* Using [chat messages](https://docs.langchain.com/oss/python/langchain/messages) as our graph state\n",
    "* Using [chat models](https://docs.langchain.com/oss/python/integrations/chat) in graph nodes\n",
    "* [Binding tools](https://docs.langchain.com/oss/python/langchain/models#tool-calling) to our chat model\n",
    "* [Executing tool calls](https://docs.langchain.com/oss/python/langchain/models#tool-execution-loop) in graph nodes \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Messages\n",
    "\n",
    "Chat models can use [messages](https://docs.langchain.com/oss/python/langchain/messages), which capture different roles within a conversation. \n",
    "\n",
    "LangChain supports various message types, including `HumanMessage`, `AIMessage`, `SystemMessage`, and `ToolMessage`. \n",
    "\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call. \n",
    "\n",
    "Let's create a list of messages. \n",
    "\n",
    "Each message can be supplied with a few things:\n",
    "\n",
    "* `content` - content of the message\n",
    "* `name` - optionally, a message author \n",
    "* `response_metadata` - optionally, a dict of metadata (e.g., often populated by model provider for `AIMessages`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "# from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Chat Models\n",
    "\n",
    "Chat models use a sequence of messages as input and support message types, as discussed above.\n",
    "\n",
    "There are [many](https://docs.langchain.com/oss/python/integrations/chat) to choose from! Let's work with OpenAI. \n",
    "\n",
    "Let's check that your `OPENAI_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2652d5ec-7602-4220-bc6e-b90783ab287b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
   "metadata": {},
   "source": [
    "We can load a chat model and invoke it with out list of messages.\n",
    "\n",
    "We can see that the result is an `AIMessage` with specific `response_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "# result = llm.invoke(messages)\n",
    "# type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Tools\n",
    "\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "\n",
    "External systems (e.g., APIs) often require a particular input schema or payload, rather than natural language. \n",
    "\n",
    "When we bind an API, for example, as a tool we given the model awareness of the required input schema.\n",
    "\n",
    "The model will choose to call a tool based upon the natural language input from the user. \n",
    "\n",
    "And, it will return an output that adheres to the tool's schema. \n",
    "\n",
    "[Many LLM providers support tool calling](https://docs.langchain.com/oss/python/integrations/chat) and [tool calling interface](https://blog.langchain.com/improving-core-tool-interfaces-and-docs-in-langchain/) in LangChain is simple. \n",
    " \n",
    "You can simply pass any Python `function` into `ChatModel.bind_tools(function)`.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a942b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's showcase a simple example of tool calling!\n",
    " \n",
    "The `multiply` function is our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f9dba",
   "metadata": {},
   "source": [
    "If we pass an input - e.g., `\"What is 2 multiplied by 3\"` - we see a tool call returned. \n",
    "\n",
    "The tool call has specific arguments that match the input schema of our function along with the name of the function to call.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"Lance\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_res in tool_call.tool_calls:\n",
    "\n",
    "    if tool_res[\"name\"] == \"multiply\":\n",
    "        result = multiply(**tool_res[\"args\"])\n",
    "\n",
    "result\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Using messages as state\n",
    "\n",
    "With these foundations in place, we can now use  [messages](https://docs.langchain.com/oss/python/langchain/overview#messages) in our graph state.\n",
    "\n",
    "Let's define our state, `MessagesState`, as a `TypedDict` with a single key: `messages`.\n",
    "\n",
    "`messages` is simply a list of messages, as we defined above (e.g., `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Reducers\n",
    "\n",
    "Now, we have a minor problem! \n",
    "\n",
    "As we discussed, each node will return a new value for our state key `messages`.\n",
    "\n",
    "But, this new value will overwrite the prior `messages` value!\n",
    " \n",
    "As our graph runs, we want to **append** messages to our `messages` state key.\n",
    " \n",
    "We can use [reducer functions](https://docs.langchain.com/oss/python/langgraph/graph-api#reducers) to address this.\n",
    "\n",
    "Reducers specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should *override it* as we saw before.\n",
    " \n",
    "But, to append messages, we can use the pre-built `add_messages` reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We simply need to annotate our `messages` key with the `add_messages` reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e574-ba15-46be-a37c-48c8052d693b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Since having a list of messages in graph state is so common, LangGraph has a pre-built  [`MessagesState`](https://docs.langchain.com/oss/python/langgraph/graph-api#messagesstate)! \n",
    "\n",
    "`MessagesState` is defined: \n",
    "\n",
    "* With a pre-build single `messages` key\n",
    "* This is a list of `AnyMessage` objects \n",
    "* It uses the `add_messages` reducer\n",
    "\n",
    "We'll usually use `MessagesState` because it is less verbose than defining a custom `TypedDict`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
   "metadata": {},
   "source": [
    "To go a bit deeper, we can see how the `add_messages` reducer works in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='4d4b6525-2f33-4119-8b6e-4963d47b8a6d'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='869a2e0d-a994-40dd-924f-f21fdf95e494'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='8a354aa8-b9fa-40a6-b7df-71c0155fc9e5')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import Dict\n",
    "    \n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    #{\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "    state[\"messages\"] = [response]\n",
    "    # state[\"messages\"].append(response)\n",
    "    return state\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
   "metadata": {},
   "source": [
    "If we pass in `Hello!`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke(input={\"messages\": [HumanMessage(content=\"Hello!\")]})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
   "metadata": {},
   "source": [
    "The LLM chooses to use a tool when it determines that the input or task requires the functionality provided by that tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_xLsOOwNowyMvDK99y2KNQib0)\n",
      " Call ID: call_xLsOOwNowyMvDK99y2KNQib0\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": [HumanMessage(content=\"Multiply 2 and 3\")]})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fbae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
