{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna\n",
    "Optuna is an automatic hyperparameter optimization software framework, particularly designed for machine learning. <br>\n",
    "It is entirely written in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepts\n",
    "Trial: A single execution of objective function. <br>\n",
    "Study: Optimization session, which is set of trials. <br>\n",
    "Parameter: A variable whose value is to be optimized\n",
    "\n",
    "\n",
    "The goal of study is to find out the optimal set of hyperparameters values through multiple trials.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to optimize: <br>\n",
    "(x - 2)^2\n",
    "\n",
    "i.e min: f(x) <br>\n",
    "f(x) = (x - 2)^2 <br>\n",
    "\n",
    "We know f(x) is minimum at x = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "import optuna\n",
    "\n",
    "# Conventionally we define the function which need to optimized as \"objective\"\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            trial: A trial object corrresponds to a single execution of the objective function and\n",
    "                   is internally instantiated upon each invocation of the function\n",
    "\n",
    "        Returns:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample the variable which needs to be optimized\n",
    "    # \"suggest\" API are called inside the objective function to obtain parameter of trial. \n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "\n",
    "    # Always return the objective function which needs to minimized\n",
    "    # In case of ML, it would be Loss \n",
    "    return (x - 2)**2\n",
    "\n",
    "# Create the study object\n",
    "study  = optuna.create_study()\n",
    "\n",
    "# Call the optimize method by passing \"objective\" function and \"n_trials\"\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter is: {'x': 1.9949253522281367}\n",
      "Best value is: 2.5752050008476984e-05\n",
      "Best trial is: FrozenTrial(number=33, state=TrialState.COMPLETE, values=[2.5752050008476984e-05], datetime_start=datetime.datetime(2023, 8, 17, 13, 58, 19, 792665), datetime_complete=datetime.datetime(2023, 8, 17, 13, 58, 19, 798175), params={'x': 1.9949253522281367}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'x': FloatDistribution(high=10.0, log=False, low=-10.0, step=None)}, trial_id=33, value=None)\n",
      "Number of trials are: 100\n"
     ]
    }
   ],
   "source": [
    "# Get the best parameters \n",
    "print(f\"Best parameter is: {study.best_params}\")\n",
    "\n",
    "# Get the best value\n",
    "print(f\"Best value is: {study.best_value}\")\n",
    "\n",
    "# Get the best trial\n",
    "print(f\"Best trial is: {study.best_trial}\")\n",
    "\n",
    "# Get num of trials\n",
    "print(f\"Number of trials are: {len(study.trials)}\")\n",
    "\n",
    "# To get all trials\n",
    "# study.trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pythonic search space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For HyperParameter sampling optuna provides the following features: <br>\n",
    "1  optuna.trial.Trial.suggest_categorical <br>\n",
    "2  optuna.trial.Trial.suggest_discrete_uniform <br>\n",
    "3  optuna.trial.Trial.suggest_float <br>\n",
    "4  optuna.trial.Trial.suggest_int <br>\n",
    "5  optuna.trial.Trial.suggest_loguniform <br>\n",
    "6  optuna.trial.Trial.suggest_uniform <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Categorical parameter\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [\"MomentumSGD\", \"Adam\"])\n",
    "    print(optimizer)\n",
    "\n",
    "    # Integer parameter\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    print(num_layers)\n",
    "\n",
    "    # Integer parameter (log)\n",
    "    num_channels = trial.suggest_int(\"num_channels\", 32, 512, log=True)\n",
    "    print(num_channels)\n",
    "\n",
    "    # Integer parameter (discretized)\n",
    "    num_units = trial.suggest_int(\"num_units\", 10, 100, step=5)\n",
    "    print(num_units)\n",
    "\n",
    "    # Floating point parameter\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 1.0)\n",
    "    print(dropout_rate)\n",
    "\n",
    "    # Floating point parameter (log)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    print(learning_rate)\n",
    "\n",
    "    # Floating point parameter (discretized)\n",
    "    drop_path_rate = trial.suggest_float(\"drop_path_rate\", 0.0, 1.0, step=0.1)\n",
    "    print(drop_path_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-17 15:11:16,065] A new study created in memory with name: no-name-ced8d171-5f8c-4a7a-be23-7b03717d0421\n",
      "[W 2023-08-17 15:11:16,070] Trial 0 failed with parameters: {'optimizer': 'MomentumSGD', 'num_layers': 1, 'num_channels': 120, 'num_units': 50, 'dropout_rate': 0.014343831891252656, 'learning_rate': 8.24688538144633e-05, 'drop_path_rate': 0.0} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-08-17 15:11:16,071] Trial 0 failed with value None.\n",
      "[W 2023-08-17 15:11:16,075] Trial 1 failed with parameters: {'optimizer': 'MomentumSGD', 'num_layers': 2, 'num_channels': 46, 'num_units': 60, 'dropout_rate': 0.6910942427081528, 'learning_rate': 0.0002123946191339557, 'drop_path_rate': 0.6000000000000001} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-08-17 15:11:16,076] Trial 1 failed with value None.\n",
      "[W 2023-08-17 15:11:16,079] Trial 2 failed with parameters: {'optimizer': 'Adam', 'num_layers': 2, 'num_channels': 355, 'num_units': 20, 'dropout_rate': 0.2616117069526859, 'learning_rate': 0.005407678060643385, 'drop_path_rate': 0.7000000000000001} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-08-17 15:11:16,080] Trial 2 failed with value None.\n",
      "[W 2023-08-17 15:11:16,084] Trial 3 failed with parameters: {'optimizer': 'Adam', 'num_layers': 2, 'num_channels': 63, 'num_units': 80, 'dropout_rate': 0.6933545727235636, 'learning_rate': 0.00011992755330276369, 'drop_path_rate': 0.0} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-08-17 15:11:16,085] Trial 3 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MomentumSGD\n",
      "1\n",
      "120\n",
      "50\n",
      "0.014343831891252656\n",
      "8.24688538144633e-05\n",
      "0.0\n",
      "MomentumSGD\n",
      "2\n",
      "46\n",
      "60\n",
      "0.6910942427081528\n",
      "0.0002123946191339557\n",
      "0.6000000000000001\n",
      "Adam\n",
      "2\n",
      "355\n",
      "20\n",
      "0.2616117069526859\n",
      "0.005407678060643385\n",
      "0.7000000000000001\n",
      "Adam\n",
      "2\n",
      "63\n",
      "80\n",
      "0.6933545727235636\n",
      "0.00011992755330276369\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note\n",
    "The difficulty of optimization increases roughly exponentially with regard to the number of parameters. That is, the number of necessary trials increases exponentially when you increase the number of parameters, so it is recommended to not add unimportant parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Efficient optimization Algorithms\n",
    "Optuna enables efficient hyperparameter optimization by adopting state-of-the-art algorithms for sampling hyperparameters and pruning efficiently unpromising trials.\n",
    "\n",
    "##### Sampling algorithms\n",
    "Samplers basically continually narrow down the search space using the records of suggested parameter values and evaluated objective values, leading to an optimal search space with giving off parameters leading to better objective values. <br>\n",
    "\n",
    "##### Sampling algorithms\n",
    "1) Grid search: <b>GridSampler</b>\n",
    "2) Random search: <b>RandomSampler</b>\n",
    "3) Tree-structured Parzen estimator: <b>TPESampler</b>\n",
    "4) CMA-ES: <b>CmaEsSampler</b>\n",
    "5) Algorithm to enable partial fixed parameters implemented in <b>PartialFixedSampler</b>\n",
    "6) Nondominated Sorting Genetic Algorithm II implemented in <b>NSGAIISampler</b>\n",
    "7) A Quasi Monte Carlo sampling algorithm implemented in <b>QMCSampler</b>\n",
    "\n",
    "The default sampler is <b>TPESampler</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Samplers\n",
    "study = optuna.create_study(sampler=<b>optuna.samplers.RandomSampler()</b>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-17 15:34:38,838] A new study created in memory with name: no-name-92f28b9b-65b4-4cfa-b7a4-2ea93614e618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampler used is: RandomSampler\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(sampler=optuna.samplers.RandomSampler())\n",
    "print(f\"Sampler used is: {study.sampler.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pruning Algorithms\n",
    "Pruners automatically stops unpromising trials at early stages of training (aka, automated early stopping).\n",
    "\n",
    "Pruning Algorithms:\n",
    "1. Median Pruning algorithm: <b>MedianPruner</b>\n",
    "2. Non-pruning algorithm: <b>NopPruner</b>\n",
    "3. Algorithm to implement pruner with tolerance implemented: <b>PatientPruner</b>\n",
    "4. Algorithm to prune specified percentile of trials implemented: <b>PercentilePruner</b>\n",
    "5. Asynchronous Successive Halving algorithm: <b>SuccessiveHalvingPruner</b>\n",
    "6. Hyperband algorithm: <b>HyperbrandPruner</b>\n",
    "7. Threshold pruning algorithm: <b>ThresholdPruner</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn on pruning feature, you need to call <i>report()</i> and <i>should_prune()</i> after <b>each</b> step of iterating training. <br>\n",
    "<i>report</i> periodically monitors the intermediate objectives values. <br>\n",
    "<i>should_prune</i> decides termination of the trial that does not meet a predefined condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    iris = sklearn.datasets.load_iris()\n",
    "    classes = list(set(iris.target))\n",
    "    train_x, valid_x, train_y, valid_y = sklearn.model_selection.train_test_split(\n",
    "        iris.data, iris.target, test_size=0.25, random_state=0\n",
    "    )\n",
    "\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-5, 1e-1, log=True)\n",
    "    clf = sklearn.linear_model.SGDClassifier(alpha=alpha)\n",
    "\n",
    "    for step in range(100):\n",
    "        clf.partial_fit(train_x, train_y, classes=classes)\n",
    "\n",
    "        # Report intermediate objective value.\n",
    "        intermediate_value = 1.0 - clf.score(valid_x, valid_y)\n",
    "        trial.report(intermediate_value, step)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return 1.0 - clf.score(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-17 15:55:53,878] A new study created in memory with name: no-name-3502495e-d54d-4df0-a46b-e0a2f06d32d1\n",
      "[I 2023-08-17 15:55:54,066] Trial 0 finished with value: 0.07894736842105265 and parameters: {'alpha': 0.008500363754434878}. Best is trial 0 with value: 0.07894736842105265.\n",
      "[I 2023-08-17 15:55:54,223] Trial 1 finished with value: 0.3421052631578947 and parameters: {'alpha': 7.412350618752943e-05}. Best is trial 0 with value: 0.07894736842105265.\n",
      "[I 2023-08-17 15:55:54,380] Trial 2 finished with value: 0.23684210526315785 and parameters: {'alpha': 0.008726733282400114}. Best is trial 0 with value: 0.07894736842105265.\n",
      "[I 2023-08-17 15:55:54,538] Trial 3 finished with value: 0.21052631578947367 and parameters: {'alpha': 5.3743226938865354e-05}. Best is trial 0 with value: 0.07894736842105265.\n",
      "[I 2023-08-17 15:55:54,696] Trial 4 finished with value: 0.052631578947368474 and parameters: {'alpha': 0.00040510090654396005}. Best is trial 4 with value: 0.052631578947368474.\n",
      "[I 2023-08-17 15:55:54,713] Trial 5 pruned. \n",
      "[I 2023-08-17 15:55:54,719] Trial 6 pruned. \n",
      "[I 2023-08-17 15:55:54,726] Trial 7 pruned. \n",
      "[I 2023-08-17 15:55:54,734] Trial 8 pruned. \n",
      "[I 2023-08-17 15:55:54,812] Trial 9 pruned. \n",
      "[I 2023-08-17 15:55:54,822] Trial 10 pruned. \n",
      "[I 2023-08-17 15:55:54,836] Trial 11 pruned. \n",
      "[I 2023-08-17 15:55:54,848] Trial 12 pruned. \n",
      "[I 2023-08-17 15:55:54,859] Trial 13 pruned. \n",
      "[I 2023-08-17 15:55:54,871] Trial 14 pruned. \n",
      "[I 2023-08-17 15:55:54,885] Trial 15 pruned. \n",
      "[I 2023-08-17 15:55:54,899] Trial 16 pruned. \n",
      "[I 2023-08-17 15:55:54,911] Trial 17 pruned. \n",
      "[I 2023-08-17 15:55:54,933] Trial 18 pruned. \n",
      "[I 2023-08-17 15:55:54,978] Trial 19 pruned. \n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which sampler and pruner should be used?\n",
    "For non deep learning task, following is the best:\n",
    "- For <i>RandomSampler</i>, <i>MedianPruner</i> is the best\n",
    "- For <i>TPESampler</i>, HyperbrandPruner</i> is the best\n",
    "\n",
    "For Deep learning tasks:\n",
    "\n",
    "\n",
    "![DeepLearning_Sampler_and_pruner](.\\Images\\Deep_learning_Sampler_Pruner.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.create_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
