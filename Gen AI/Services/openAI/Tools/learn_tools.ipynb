{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc84e9f",
   "metadata": {},
   "source": [
    "Use tools like remote MCP servers or web search to extend the model's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe4fbdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "# load_dotenv(dotenv_path=\"../.env\")\n",
    "load_dotenv()\n",
    "\n",
    "open_api_key = os.getenv(\"open_api_key\")\n",
    "\n",
    "openAI_params = {\n",
    "    'api_key': open_api_key\n",
    "}\n",
    "client = OpenAI(**openAI_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c9973",
   "metadata": {},
   "source": [
    "#### Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d1824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One positive story from **today (Tuesday, December 16, 2025)**: **Climate-focused activists are pushing for a new “Climate and Planetary Health” Nobel Prize — and they’ve offered to fund the first €1 million prize endowment if the Nobel Committee agrees.** ([goodgoodgood.co](https://www.goodgoodgood.co/articles/good-news-this-week-december-13-2025?utm_source=openai))\n",
      "\n",
      "Why it’s uplifting: it’s a concrete attempt to elevate and reward climate solutions at the same global-prestige level as the existing Nobel categories, potentially boosting attention, legitimacy, and momentum for effective climate action. ([goodgoodgood.co](https://www.goodgoodgood.co/articles/good-news-this-week-december-13-2025?utm_source=openai))\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-5.2\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    input=\"What was a positive news story from today?\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6252064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e1d0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa84c39a",
   "metadata": {},
   "source": [
    "#### Function Calling\n",
    "Note: LLM will only generate the Argument for the Function, it is developer responsibility to call the function, appends its output to the input of LLM and call LLM again to generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04be53e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"fc_0427b20d5692be9b006941419504588193a0e8cb3179ccb3ea\",\n",
      "  \"arguments\": \"{\\\"location\\\":\\\"Paris, France\\\"}\",\n",
      "  \"call_id\": \"call_issLXdbvlnCYZWf2NghiUL2Y\",\n",
      "  \"name\": \"get_weather\",\n",
      "  \"type\": \"function_call\",\n",
      "  \"status\": \"completed\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def get_weather(location: str) -> str:\n",
    "    # Dummy implementation for illustration\n",
    "    return f\"The current temperature in {location} is 100Kg.\"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current temperature for a given location.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"City and country e.g. Bogotá, Colombia\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "        \"strict\": True,\n",
    "    },\n",
    "]\n",
    "\n",
    "input_list = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather like in Paris today?\"}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5.2\",\n",
    "    input=input_list,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "print(response.output[0].to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37850a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final input:\n",
      "[{'role': 'user', 'content': 'What is the weather like in Paris today?'}, ResponseFunctionToolCall(id='fc_0427b20d5692be9b006941419504588193a0e8cb3179ccb3ea', arguments='{\"location\":\"Paris, France\"}', call_id='call_issLXdbvlnCYZWf2NghiUL2Y', name='get_weather', type='function_call', status='completed'), {'type': 'function_call_output', 'call_id': 'call_issLXdbvlnCYZWf2NghiUL2Y', 'output': '{\"weather\": \"The current temperature in Paris, France is 100Kg.\"}'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save function call outputs for subsequent requests\n",
    "input_list += response.output\n",
    "\n",
    "# Call the function based on the model's request\n",
    "for item in response.output:\n",
    "    if item.type == \"function_call\":\n",
    "        if item.name == \"get_weather\":\n",
    "            # 3. Execute the function logic for get_weather\n",
    "            weather = get_weather(**json.loads(item.arguments))\n",
    "            \n",
    "            # 4. Provide function call results to the model\n",
    "            input_list.append({\n",
    "                \"type\": \"function_call_output\",\n",
    "                \"call_id\": item.call_id,\n",
    "                \"output\": json.dumps({\n",
    "                  \"weather\": weather\n",
    "                })\n",
    "            })\n",
    "\n",
    "print(\"Final input:\")\n",
    "print(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47287f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function_call_output',\n",
       " 'call_id': 'call_issLXdbvlnCYZWf2NghiUL2Y',\n",
       " 'output': '{\"weather\": \"The current temperature in Paris, France is 100Kg.\"}'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2de5f998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output:\n",
      "{\n",
      "  \"id\": \"resp_0427b20d5692be9b00694141a073108193bcb0444a8a695dd0\",\n",
      "  \"created_at\": 1765884320.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": \"Respond only with a output generated by a tool.\",\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-5-2025-08-07\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"rs_0427b20d5692be9b00694141a0e4288193bbb9c54d07d74e73\",\n",
      "      \"summary\": [],\n",
      "      \"type\": \"reasoning\",\n",
      "      \"status\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_0427b20d5692be9b00694141b5ab8881939a0b174d0f2f994e\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"{\\\"weather\\\":\\\"The current temperature in Paris, France is 100Kg.\\\"}\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"name\": \"get_weather\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"location\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"City and country e.g. Bogotá, Colombia\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"location\"\n",
      "        ],\n",
      "        \"additionalProperties\": false\n",
      "      },\n",
      "      \"strict\": true,\n",
      "      \"type\": \"function\",\n",
      "      \"description\": \"Get current temperature for a given location.\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 1.0,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": \"medium\",\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 126,\n",
      "    \"output_tokens\": 1174,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 1152\n",
      "    },\n",
      "    \"total_tokens\": 1300,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"background\": false,\n",
      "  \"billing\": {\n",
      "    \"payer\": \"developer\"\n",
      "  },\n",
      "  \"max_tool_calls\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"prompt_cache_retention\": null,\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"store\": true,\n",
      "  \"top_logprobs\": 0\n",
      "}\n",
      "\n",
      "{\"weather\":\"The current temperature in Paris, France is 100Kg.\"}\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    instructions=\"Respond only with a output generated by a tool.\",\n",
    "    tools=tools,\n",
    "    input=input_list,\n",
    ")\n",
    "\n",
    "# 5. The model should be able to give a response!\n",
    "print(\"Final output:\")\n",
    "print(response.model_dump_json(indent=2))\n",
    "print(\"\\n\" + response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c637783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52c6fb1d",
   "metadata": {},
   "source": [
    "#### MCP Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25f6bb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDIO and Streamable HTTP.\n"
     ]
    }
   ],
   "source": [
    "resp = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"mcp\",\n",
    "            \"server_label\": \"deepwiki\",\n",
    "            \"server_url\": \"https://mcp.deepwiki.com/mcp\",\n",
    "            \"require_approval\": {\n",
    "                \"never\": {\n",
    "                    \"tool_names\": [\"ask_question\", \"read_wiki_structure\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    "    input=\"What transport protocols does the 2025-03-26 version of the MCP spec (modelcontextprotocol/modelcontextprotocol) support?\",\n",
    ")\n",
    "\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c540cfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'mcp_047997566650401900694144fbebac8193b262ee69b8b5412e',\n",
       " 'status': 'completed',\n",
       " 'type': 'mcp_call',\n",
       " 'approval_request_id': None,\n",
       " 'arguments': '{\"repoName\":\"modelcontextprotocol/modelcontextprotocol\",\"question\":\"What transport protocols does the 2025-03-26 version of the MCP specification support?\"}',\n",
       " 'error': None,\n",
       " 'name': 'ask_question',\n",
       " 'output': 'The 2025-03-26 version of the Model Context Protocol (MCP) specification supports two primary transport protocols: STDIO and Streamable HTTP . These transports define how clients and servers communicate and exchange messages .\\n\\n## Supported Transport Protocols\\n\\n### STDIO Transport\\nThe STDIO transport uses standard input/output streams for direct process communication . This is typically used for local processes running on the same machine, offering optimal performance without network overhead . In this model, the client launches the MCP server as a subprocess, and messages are exchanged via `stdin` and `stdout` . Messages are JSON-RPC requests, notifications, or responses, delimited by newlines .\\n\\n### Streamable HTTP Transport\\nThe Streamable HTTP transport utilizes HTTP POST for client-to-server messages and can optionally use Server-Sent Events (SSE) for streaming server-to-client messages . This transport enables communication with remote servers and supports standard HTTP authentication methods, including OAuth  . The server provides a single HTTP endpoint that supports both POST and GET methods .\\n\\n## Notes\\nThe `docs/docs.json` file lists the available specification versions, including the 2025-03-26 version, and points to `specification/2025-03-26/basic/transports` as a relevant document for this version . While the provided snippet for `docs/specification/draft/basic/transports.mdx` is a draft, it explicitly mentions that Streamable HTTP replaces the HTTP+SSE transport from protocol version 2024-11-05 . The `docs/docs/learn/architecture.mdx` file confirms the existence of both STDIO and Streamable HTTP transports in the general MCP architecture . The `docs/specification/2025-06-18/changelog.mdx` also refers to the `Streamable HTTP` transport in the context of the 2025-03-26 version .\\n\\nWiki pages you might want to explore:\\n- [Integration Patterns (modelcontextprotocol/modelcontextprotocol)](/wiki/modelcontextprotocol/modelcontextprotocol#4.3)\\n\\nView this search on DeepWiki: https://deepwiki.com/search/what-transport-protocols-does_a434de92-80a5-474e-89b9-befdcbbd9cb1\\n',\n",
       " 'server_label': 'deepwiki'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.output[2].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5d0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23f134f3",
   "metadata": {},
   "source": [
    "#### Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc88357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the calculations:\n",
      "- 4 × 3.82 = 15.28\n",
      "- Square root of 15.28 ≈ 3.91\n",
      "- Square root of 3.91 ≈ 1.98\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"open_api_key\")\n",
    ")\n",
    "\n",
    "container = client.containers.create(name=\"test-container\", memory_limit=\"1g\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    tools=[{\n",
    "        \"type\": \"code_interpreter\",\n",
    "        \"container\": container.id\n",
    "    }],\n",
    "    tool_choice=\"required\",\n",
    "    input=\"use the python tool to calculate what is 4 * 3.82. and then find its square root and then find the square root of that result\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a41813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ci_065e8a6b3360d26b0069416d509d6081909d18c032e08f21f3',\n",
       " 'code': 'import math\\n\\n# Calculate 4 * 3.82\\nresult1 = 4 * 3.82\\n\\n# Find the square root of result1\\nresult2 = math.sqrt(result1)\\n\\n# Find the square root of result2\\nfinal_result = math.sqrt(result2)\\n\\nresult1, result2, final_result',\n",
       " 'container_id': 'cntr_69416d4c0320819085ab0530010dd29d0320a7899f0e1758',\n",
       " 'outputs': None,\n",
       " 'status': 'completed',\n",
       " 'type': 'code_interpreter_call'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04a371b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import math\n",
      "\n",
      "# Calculate 4 * 3.82\n",
      "result1 = 4 * 3.82\n",
      "\n",
      "# Find the square root of result1\n",
      "result2 = math.sqrt(result1)\n",
      "\n",
      "# Find the square root of result2\n",
      "final_result = math.sqrt(result2)\n",
      "\n",
      "result1, result2, final_result\n"
     ]
    }
   ],
   "source": [
    "print(response.output[0].to_dict()['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac67d3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_065e8a6b3360d26b0069416d57f2848190a9593c8735f0e67e',\n",
       " 'content': [{'annotations': [],\n",
       "   'text': 'Here are the calculations:\\n- 4 × 3.82 = 15.28\\n- Square root of 15.28 ≈ 3.91\\n- Square root of 3.91 ≈ 1.98',\n",
       "   'type': 'output_text',\n",
       "   'logprobs': []}],\n",
       " 'role': 'assistant',\n",
       " 'status': 'completed',\n",
       " 'type': 'message'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[1].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50e9a1f",
   "metadata": {},
   "source": [
    "When working with code interpreter, the model can create its own file. For Ex: If you ask it to create a plot, or create a csv file,\n",
    "it will create these images directly on your container.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"id\": \"msg_682d514e268c8191a89c38ea318446200f2610a7ec781a4f\",\n",
    "    \"content\": [\n",
    "        {\n",
    "            \"annotations\": [\n",
    "                {\n",
    "                    \"file_id\": \"cfile_682d514b2e00819184b9b07e13557f82\",\n",
    "                    \"index\": null,\n",
    "                    \"type\": \"container_file_citation\",\n",
    "                    \"container_id\": \"cntr_682d513bb0c48191b10bd4f8b0b3312200e64562acc2e0af\",\n",
    "                    \"end_index\": 0,\n",
    "                    \"filename\": \"cfile_682d514b2e00819184b9b07e13557f82.png\",\n",
    "                    \"start_index\": 0\n",
    "                }\n",
    "            ],\n",
    "            \"text\": \"Here is the histogram of the RGB channels for the uploaded image. Each curve represents the distribution of pixel intensities for the red, green, and blue channels. Peaks toward the high end of the intensity scale (right-hand side) suggest a lot of brightness and strong warm tones, matching the orange and light background in the image. If you want a different style of histogram (e.g., overall intensity, or quantized color groups), let me know!\",\n",
    "            \"type\": \"output_text\",\n",
    "            \"logprobs\": []\n",
    "        }\n",
    "    ],\n",
    "    \"role\": \"assistant\",\n",
    "    \"status\": \"completed\",\n",
    "    \"type\": \"message\"\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "To download these file, hit the GET API endpoint <br>\n",
    "`curl https://api.openai.com/v1/containers/{container_id}/files/{file_id}/content \\\n",
    "  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e199fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fdae13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4840f2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62eff57e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_AI_python3130_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
