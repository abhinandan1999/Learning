{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "open_api_key = os.getenv(\"open_api_key\")\n",
    "\n",
    "openAI_params = {\n",
    "    'api_key': open_api_key\n",
    "}\n",
    "client = OpenAI(**openAI_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured Outputs\n",
    "Structured Outputs is a feature that ensures the model will always generate responses that adhere to your supplied JSON Schema, so you don't need to worry about the model omitting a required key, or hallucinating an invalid enum value.\n",
    "\n",
    "Some benefits of Structured Outputs include:\n",
    "\n",
    "- Reliable type-safety: No need to validate or retry incorrectly formatted responses\n",
    "- Explicit refusals: Safety-based model refusals are now programmatically detectable\n",
    "- Simpler prompting: No need for strongly worded prompts to achieve consistent formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Details about response\n",
      "------------------------------\n",
      "Model: gpt-4o-2024-08-06\n",
      "\n",
      "\n",
      "------------------------------\n",
      "Details about Results\n",
      "------------------------------\n",
      "Parsed Result: name='Science Fair' date='Friday' participants=['Alice', 'Bob']\n",
      "Content Result: {\"name\":\"Science Fair\",\"date\":\"Friday\",\"participants\":[\"Alice\",\"Bob\"]}\n",
      "\n",
      "\n",
      "------------------------------\n",
      "Details about Usage\n",
      "------------------------------\n",
      "Result: {'completion_tokens': 18, 'prompt_tokens': 92, 'total_tokens': 110, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "    ],\n",
    "    max_tokens=50,\n",
    "    response_format=CalendarEvent\n",
    ")\n",
    "\n",
    "print(\"-\"*30, \"Details about response\", \"-\"*30, sep='\\n')\n",
    "print(f\"Model: {completion.model}\")\n",
    "\n",
    "print(\"\\n\", \"-\"*30, \"Details about Results\", \"-\"*30, sep='\\n')\n",
    "print(f\"Parsed Result: {completion.choices[0].message.parsed}\")\n",
    "print(f\"Content Result: {completion.choices[0].message.content}\")\n",
    "\n",
    "\n",
    "print(\"\\n\", \"-\"*30, \"Details about Usage\", \"-\"*30, sep='\\n')\n",
    "print(f\"Result: {completion.usage.to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the prompt usage with chat completion call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Details about response\n",
      "------------------------------\n",
      "Model: gpt-4o-2024-08-06\n",
      "\n",
      "\n",
      "------------------------------\n",
      "Details about Results\n",
      "------------------------------\n",
      "Result: Event: Science fair  \n",
      "Participants: Alice and Bob  \n",
      "Date: Friday  \n",
      "\n",
      "\n",
      "------------------------------\n",
      "Details about Usage\n",
      "------------------------------\n",
      "Result: {'completion_tokens': 16, 'prompt_tokens': 28, 'total_tokens': 44, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "    ],\n",
    "    max_tokens=50\n",
    ")\n",
    "\n",
    "print(\"-\"*30, \"Details about response\", \"-\"*30, sep='\\n')\n",
    "print(f\"Model: {completion.model}\")\n",
    "\n",
    "print(\"\\n\", \"-\"*30, \"Details about Results\", \"-\"*30, sep='\\n')\n",
    "print(f\"Result: {completion.choices[0].message.content}\")\n",
    "\n",
    "print(\"\\n\", \"-\"*30, \"Details about Usage\", \"-\"*30, sep='\\n')\n",
    "print(f\"Result: {completion.usage.to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the extraction json schema in prompt usage with chat completion call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Details about response\n",
      "------------------------------\n",
      "Model: gpt-4o-2024-08-06\n",
      "\n",
      "\n",
      "------------------------------\n",
      "Details about Results\n",
      "------------------------------\n",
      "Result: {\n",
      "\"name\": \"Science Fair\",\n",
      "\"date\": \"Friday\",\n",
      "\"participants\": [\"Alice\", \"Bob\"]\n",
      "}\n",
      "\n",
      "\n",
      "------------------------------\n",
      "Details about Usage\n",
      "------------------------------\n",
      "Result: {'completion_tokens': 24, 'prompt_tokens': 48, 'total_tokens': 72, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n"
     ]
    }
   ],
   "source": [
    "json_prompt = f\"\"\"\n",
    "Extract the event information in following json schema.\n",
    "\n",
    "{{\n",
    "\"name\": \"\",\n",
    "\"date\": \"\",\n",
    "\"participants\": [\"\"]\n",
    "}}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "completion_json = client.chat.completions.create(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"{json_prompt}\"},\n",
    "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
    "    ],\n",
    "    max_tokens=50\n",
    ")\n",
    "\n",
    "print(\"-\"*30, \"Details about response\", \"-\"*30, sep='\\n')\n",
    "print(f\"Model: {completion_json.model}\")\n",
    "\n",
    "print(\"\\n\", \"-\"*30, \"Details about Results\", \"-\"*30, sep='\\n')\n",
    "print(f\"Result: {completion_json.choices[0].message.content}\")\n",
    "\n",
    "print(\"\\n\", \"-\"*30, \"Details about Usage\", \"-\"*30, sep='\\n')\n",
    "print(f\"Result: {completion_json.usage.to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "1. Chat completion without response format uses less tokens\n",
    "2. Chat completion with json response format defined in prompt uses more token that 1\n",
    "3. Chat completion with response format defined uses the hhighest token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of structured output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MathReasoning(steps=[Step(explanation=\"We start by isolating the term with the variable, 8x. To do this, we need to eliminate the constant term on the left side of the equation. The equation is 8x + 7 = -23. We'll subtract 7 from both sides to start the isolation of 8x.\", output='8x + 7 - 7 = -23 - 7'), Step(explanation='Subtracting 7 from both sides, we eliminate the 7 on the left, which simplifies our equation to 8x on the left side.', output='8x = -30'), Step(explanation=\"Next, we need to solve for x. This means we need x to stand alone on one side of the equation. 8x means 8 multiplied by x, so we'll divide both sides of the equation by 8 to isolate x.\", output='x = -30 / 8'), Step(explanation='Simplifying the fraction -30/8 by dividing the numerator and the denominator by their greatest common divisor, which is 2, we get -15/4.', output='x = -15/4')], final_answer='x = -15/4')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: str\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
    "    ],\n",
    "    response_format=MathReasoning,\n",
    ")\n",
    "\n",
    "math_reasoning = completion.choices[0].message.parsed\n",
    "math_reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Structured Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResearchPaperExtraction(title='The Role of Bhagavad Gita in Modern Life', authors=['Ravi Shankar', 'Leela Menon'], abstract=\"The Bhagavad Gita, a 700-verse Hindu scripture, is part of the Indian epic Mahabharata. It is a conversation between prince Arjuna and the god Krishna, who serves as his charioteer. This discourse, which takes place on the battlefield of Kurukshetra, addresses the moral and philosophical dilemmas faced by Arjuna. In this paper, we explore the Gita's applicability to modern life, focusing on its teachings about duty, righteousness, and devotion. We analyze how the Gita's insights can be integrated into contemporary ethical and spiritual discussions, offering timeless guidance for dealing with today's challenges.\", keywords=['Bhagavad Gita', 'philosophy', 'ethics', 'spirituality', 'modern life'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ResearchPaperExtraction(BaseModel):\n",
    "    title: str\n",
    "    authors: list[str]\n",
    "    abstract: str\n",
    "    keywords: list[str]\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert at structured data extraction. You will be given unstructured text from a research paper and should convert it into the given structure.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Bhagvad gita\"}\n",
    "    ],\n",
    "    response_format=ResearchPaperExtraction,\n",
    ")\n",
    "\n",
    "research_paper = completion.choices[0].message.parsed\n",
    "research_paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle the edge case\n",
    "In some cases, the model might not generate a valid response that matches the provided JSON schema.\n",
    "\n",
    "This can happen in the case of a `refusal`, if the model refuses to answer for safety reasons, or if for example you reach a max tokens limit and the response is incomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResearchPaperExtraction(title='Chatbots in Mental Health: Bridging the Gap between Technology and Therapy', authors=['Emily R. Watson', 'James L. Nguyen', 'Sophia M. Patel'], abstract='The integration of chatbot technology in mental health services presents a novel approach to enhancing patient engagement and accessibility. This paper explores the potential of chatbots as a supplementary tool for mental health support, examining their benefits, limitations, and the ethical considerations involved. Through a review of existing literature and analysis of current chatbot applications, we identify key areas where chatbots can contribute to mental health treatment, especially in resource-limited environments. Our findings suggest that, while chatbots cannot replace traditional therapy models, they can effectively complement them by offering continuous support and assisting therapists in tracking patient progress.', keywords=['chatbot', 'mental health', 'therapy', 'artificial intelligence', 'ethics'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ResearchPaperExtraction(BaseModel):\n",
    "    title: str\n",
    "    authors: list[str]\n",
    "    abstract: str\n",
    "    keywords: list[str]\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Do your thing\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"}\n",
    "    ],\n",
    "    response_format=ResearchPaperExtraction,\n",
    ")\n",
    "\n",
    "message = completion.choices[0].message\n",
    "\n",
    "# If the model refuses to respond, you will get a refusal message\n",
    "if (message.refusal):\n",
    "  print(math_reasoning.refusal)\n",
    "else:\n",
    "  research_paper = message.parsed\n",
    "\n",
    "research_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured output can also be obtained using chat.completion.create functions\n",
    "\n",
    "```\n",
    "response_format: { \"type\": \"json_schema\", \"json_schema\": â€¦ , \"strict\": true }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"steps\":[{\"explanation\":\"The equation is 8x + 7 = -23. The goal is to solve for x. The first step is to isolate the term containing x on one side of the equation. To do this, subtract 7 from both sides of the equation.\",\"output\":\"8x + 7 - 7 = -23 - 7\"},{\"explanation\":\"Simplify both sides of the equation. On the left side, 7 - 7 cancels out, and on the right side, we calculate -23 - 7.\",\"output\":\"8x = -30\"},{\"explanation\":\"Now, the equation is 8x = -30. To solve for x, divide both sides of the equation by 8, which is the coefficient of x.\",\"output\":\"x = -30 / 8\"},{\"explanation\":\"Simplify -30 / 8. The greatest common divisor of 30 and 8 is 2. Divide both the numerator and the denominator by 2 to simplify the fraction.\",\"output\":\"x = -15 / 4\"},{\"explanation\":\"Thus, the solution to the equation 8x + 7 = -23 is x = -15/4.\",\"output\":\"x = -15/4\"}],\"final_answer\":\"x = -15/4\"}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\"},\n",
    "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"}\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_schema\",\n",
    "        \"json_schema\": {\n",
    "            \"name\": \"math_response\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\", # Root(First) should be object\n",
    "                \"properties\": {\n",
    "                    \"steps\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"explanation\": {\"type\": \"string\"},\n",
    "                                \"output\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"required\": [\"explanation\", \"output\"],\n",
    "                            \"additionalProperties\": False\n",
    "                        }\n",
    "                    },\n",
    "                    \"final_answer\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"steps\", \"final_answer\"], # Define the properties which is required\n",
    "                \"additionalProperties\": False # controls whether it is allowable for an object to contain additional keys / values that were not defined in the JSON Schema.\n",
    "            },\n",
    "        \"strict\": True\n",
    "        }\n",
    "    }\n",
    "    )\n",
    "except Exception as e:\n",
    "    response = None\n",
    "    print(e)\n",
    "\n",
    "if response:\n",
    "    content = response.choices[0].message.content\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate the schema of content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel, ValidationError\n",
    "from typing import List\n",
    "\n",
    "# Define types that match the JSON Schema using pydantic models\n",
    "class Step(BaseModel):\n",
    "  explanation: str\n",
    "  output: str\n",
    "\n",
    "class Solution(BaseModel):\n",
    "  steps: List[Step]\n",
    "  final_answer: str\n",
    "\n",
    "\n",
    "try:\n",
    "  # Parse and validate the response content\n",
    "  solution = Solution.model_validate_json(content)\n",
    "  print(solution)\n",
    "except ValidationError as e:\n",
    "  # Handle validation errors\n",
    "  print(e.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supported Schemas\n",
    "- String\n",
    "- Number\n",
    "- Boolean\n",
    "- Integer\n",
    "- Object\n",
    "- Array\n",
    "- Enum\n",
    "- anyOf\n",
    "\n",
    "Note: The root level object of a schema must be an `object`, and not use `anyOf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_AI_python3130_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
